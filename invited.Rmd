---
title: "Invited Speakers"
output:
  html_document:
    theme: cosmo
---

<style type="text/css">
h1.title {
  font-size: 36px;
  color: DarkRed;
  text-align: center;
}
</style>

<!-- # Adaptive Designs and Multiple Testing Procedures Workshop -->

<!-- ## Invited Speakers -->

<br><br>



### Keynote speaker: **Dominic Magirr (Novartis Pharma AG)**

<hr>

<div align="center">
![](images/dominic_magirr.jpg){width=25%}
</div>

<!-- Dr. **Emily Johnson** is a renowned statistician and expert in adaptive designs for clinical trials. She received her Ph.D. in Biostatistics from XYZ University and has over 15 years of experience in the field. Dr. Johnson has published numerous articles on adaptive trial designs and has been invited to speak at various international conferences. Her research focuses on developing innovative statistical methods for improving the efficiency and ethical aspects of clinical trials. -->

<br>

<h3>**Deconstructing the Max-combo Test**</h3>



The Max-Combo Test (Lin et al., 2020) is an adaptive procedure to select the best test statistic from a small prespecified set of candidates. It includes a correction for multiplicity. Proposed applications include clinical trials in oncology when there is prior uncertainty regarding the commonly made proportional hazards assumption. In this context, the candidate set of test statistics usually come from the Fleming-Harrington rho-gamma family of weighted log-rank statistics. In some of the candidate test statistics, the weighting is tilted towards events occurring in the early part of follow up, whereas in others it is tilted towards events in the later part of follow up. The overall procedure is therefore robust to a wide range of treatment effect patterns. 

In this talk I shall take a close look at the Max-Combo Test, using recently proposed visualization techniques (Jimenez et al., 2023) to explain some of its counter-intuitive properties, as pointed out in recent publications (Freidlin & Korn, 2019). The same visualization techniques can be used to re-evaluate weighted log-rank tests in the broader context of the estimand framework in clinical trials. 

References

- Lin, R.S., Lin, J., Roychoudhury, S., Anderson, K.M., Hu, T., Huang, B., Leon, L.F., Liao, J.J., Liu, R., Luo, X. and Mukhopadhyay, P., 2020. Alternative analysis methods for time to event endpoints under nonproportional hazards: a comparative analysis. Statistics in Biopharmaceutical Research, 12(2), pp.187-198

- Fleming, T.R. and Harrington, D.P., 1981. A class of hypothesis tests for one and two sample censored survival data. Communications in Statistics-Theory and Methods, 10(8), pp.763-794.

- Jiménez, J.L., Barrott, I., Gasperoni, F. and Magirr, D., 2023. Visualizing hypothesis tests in survival analysis under anticipated delayed effects. arXiv preprint arXiv:2304.08087.

- Freidlin, B. and Korn, E.L., 2019. Methods for accommodating nonproportional hazards in clinical trials: ready for the primary analysis?. Journal of Clinical Oncology, 37(35), p.3455.

&nbsp;


### Keynote speaker: **Annette Kopp-Schneider (German Cancer Research Center)**
<hr>

<div align="center">
![](images/Annette_Kopp.jpg){width=25%}

</div>

</br>

<h3>**Borrowing from external information in clinical trials: methods, benefits and limitations**</h3>


When trials can only be performed with small sample sizes as, for example, in the situation of precision medicine where patients cohorts are defined by a specific combination of biomarker and targeted therapy, borrowing information from historical data is currently discussed as an approach to improve the efficiency of the trial. In this context, borrowing information is often also referred to as evidence synthesis or extrapolation, where external data could be historical data or another source of co-data.
A number of approaches for borrowing from external data that dynamically discount the amount of information transferred from external data based on the discrepancy between the external and current data have been proposed. We will present two selected approaches. The robust mixture prior (Schmidli et al, 2014) is a popular method. It is a weighted mixture of an informative and a robust prior, equivalent to a meta-analytic-combined analysis of historical and new data, assuming that parameters are exchangeable across trials. The power prior approach incorporates external data in the prior used for analysis of the current data. This prior is proportional to the likelihood of the external data raised to the power of a weight parameter. An Empirical Bayes approach for the estimation of the weight parameter from the similarity of external and current data has been proposed by Gravestock et al. (2017).

We will discuss the frequentist operating characteristics (FOC) of trials using these two adaptive borrowing approaches, evaluating type I error rate and power as well as Mean Squared Error. Use of the robust mixture prior requires the selection of the mixture weight, the mean and the variance of the robust component and we will discuss the impact of the selection on FOC. The concept of prior effective sample size facilitates quantification and communication of prior information by equating it to a sample size. When prior information arises from historical observations, the traditional approach identifies the ESS with a historical sample size, a measure that is independent of the current observed data, and thus does not capture an actual loss of information induced by the prior in case of prior-data conflict. The effective current sample size of a prior (Wiesenfarth and Calderazzo 2020) is introduced which relates prior impact to the number of (virtual) samples from the current data model. All aspects that will be discussed show that in the frequentist perspective borrowing cannot be beneficial for any possible true parameter value. However, benefits can be obtained if prior information is reliable and consistent.

References

- Gravestock I, Held L (2017). Adaptive power priors with empirical Bayes for clinical trials. Pharmaceutical Statistics 16:349-360.

- Schmidli, H., Gsteiger, S., Roychoudhury, S., O'Hagan, A., Spiegelhalter, D., Neuenschwander, B. (2014). Robust meta‐analytic‐predictive priors in clinical trials with historical control information. Biometrics, 70(4), 1023-1032.

- Wiesenfarth M, Calderazzo S (2020). Quantification of prior impact in terms of effective current sample size. Biometrics 76(1), 326-336.



&nbsp;


### Invited Sessions

<hr>

<h3>**Methodological and practical outcomes from the Adaptive Designs Working Group of the MRC-NIHR Trials Methodology Research Partnership**</h3>

<br>

<!-- Speakers: -->

<!-- <table cellspacing="0" cellpadding="0" table-layout="fixed" width="100%" word-wrap="break-word"> -->
<!-- <thead> -->
<!--   <tr> -->
<!--     <td align="center" width="200"><b>TBA</b></td> -->
<!--     <td align="center" width="200"><b>Estimation after adaptive designs</b></td> -->
<!--     <td align="center" width="200"><b>Making adaptive designs more accessible. A practical adaptive designs toolkit</b></td> -->
<!--   </tr> -->
<!-- </thead> -->
<!-- <tbody> -->
<!--   <tr> -->
<!--     <th><img src="images/faye_williamson.jpg" alt="faye_williamson" width="150"></th> -->
<!--     <th><img src="images/david-robertson.jpg" alt="david-robertson" width="150"></th> -->
<!--     <th><img src="images/munya_dimairo.jpg"   alt="munya_dimairo" width="150"></th> -->
<!--   </tr>   -->
<!--   <tr> -->
<!--     <td align="center"><b>Faye Williamson</b></td> -->
<!--     <td align="center"><b>David Robertson</b></td> -->
<!--     <td align="center"><b>Munya Dimairo</b></td> -->
<!--   </tr> -->
<!--   <tr> -->
<!--     <td align="center">Newcastle University</td> -->
<!--     <td align="center">University of Cambridge</td> -->
<!--     <td align="center">University of Sheffield</td> -->
<!--   </tr> -->

<!-- </tbody> -->
<!-- </table> -->

<table cellspacing="0" cellpadding="0" table-layout="fixed" width="100%" word-wrap="break-word">
<tbody>
  
  <tr>
    <td align="center" width="275"><img src="images/nina_wilson.jpg" alt="nina_williamson" width="125"></td>
    <td><i><h4> Exploring current practices in adaptive trials: patient information sheets, costing, and efficiently conducting interim analyses</h4></i><br><b>Faye Williamson</b> (Newcastle University)</td>
  </tr>
  
  <tr>
    <td align="center"><img src="images/david-robertson.jpg" alt="david-robertson" width="125"></td>
    <td><i><h4>Estimation after adaptive designs</h4></i><br><b>David Robertson</b> (University of Cambridge)</td>
  </tr>  
  
  <tr>
    <td align="center"><img src="images/munya_dimairo.jpg"   alt="munya_dimairo" width="125"></td>
    <td><i><h4>Making adaptive designs more accessible. A practical adaptive designs toolkit</h4></i> <br><b>Munya Dimairo</b> (University of Sheffield)</td>
  </tr>

</tbody>
</table>


<!-- - Faye Williamson (Newcastle University) -->
<!-- - David Robertson (MRC Biostatistics Unit, University of Cambridge) -->
<!-- - Munya Dimairo (University of Sheffield) -->

<br><br><br>

<h3>**Practical experiences of using software to design clinical trials using simulations**</h3>

<!-- Speakers: -->
<br>

<!-- cellspacing="0" cellpadding="0" table-layout="fixed" width="100%" word-wrap="break-word" -->

<table cellspacing="0" cellpadding="0" table-layout="fixed" width="100%" word-wrap="break-word">
<tbody>
  
  <tr>
    <td align="center" width="275"><img src="images/peter_jacko.jpg" alt="peter_jacko" width="125"></td>
    <td><h4><i>Using the "SIMulating PLatform trials Efficiently" (SIMPLE) R package to develop a simulator for a bespoke platform trial</h4></i> <br><b>Peter Jacko</b> (Berry Consultants)</td>
  </tr>
  
  <tr>
    <td align="center"><img src="images/gernot_wassmer.jpg" alt="david-robertson" width="125"><img src="images/friedrich_pahlke.jpg"   alt="friedrich_pahlke" width="125"></td>
    <td><i><h4>Flexible Clinical Trial Planning with the R Package rpact</h4></i> <br><b>Gernot Wassmer \& Friedrich Pahlke</b> (RPACT)</td>
  </tr>  
  
  <!-- <tr> -->
  <!--   <td align="center"><img src="images/friedrich_pahlke.jpg"   alt="friedrich_pahlke" width="125"></td> -->
  <!--   <td><i><h4>Flexible Clinical Trial Planning with the R Package rpact</h4></i> <br><b>Friedrich Pahlke</b> (RPACT)</td> -->
  <!-- </tr> -->
  
  <tr>
    <td align="center"><img src="images/tobias_mielke.jpg"   alt="tobias_mielke" width="125"></td>
    <td><i><h4>Design or simulation: What comes first?</h4></i> <br><b>Tobias Mielke</b> (Janssen)</td>
  </tr>
  
  <tr>
    <td align="center"><img src="images/daniel_sabanes.jpg"   alt="daniel_sabanes" width="125"></td>
    <td><i><h4>Discussant</h4></i> <br><b>Daniel Sabanés Bové</b> (Roche)</td>
  </tr>

</tbody>
</table>



<!-- - Peter Jacko (Berry Consultants) -->
<!-- - Gernot Wassmer (RPACT) -->
<!-- - Friedrich Pahlke (RPACT) -->
<!-- - Tobias Mielke (Janssen) -->
<!-- - Daniel Sabanés Bové (Roche) -->